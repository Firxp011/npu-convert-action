name: NPU Model Conversion

on:
  workflow_dispatch:
    inputs:
      civitai_version_id:
        description: "Civitai modelVersionId (e.g. 90854). Can be found in URL bar."
        required: true
        type: string
      filename:
        description: "Save as (e.g. models/my.safetensors). Must end with .safetensors"
        required: true
        default: "models/model.safetensors"
        type: string
      clip_skip:
        description: "CLIP skip"
        required: true
        default: "2"
        type: choice
        options: ["1", "2"]
      min_soc:
        description: "min | 8gen1 | 8gen2"
        required: true
        default: "8gen2"
        type: choice
        options: ["min", "8gen1", "8gen2"]

jobs:
  convert:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    steps:
      - name: Checkout (with LFS)
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Prepare folders
        run: |
          mkdir -p models tools

      - name: Install deps
        run: |
          sudo apt-get update
          sudo apt-get install -y unzip zip curl

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Download npuconvert scripts
        run: |
          cd tools
          curl -L -o npuconvert.zip "https://chino.icu/local-dream/npuconvert.zip"
          unzip -q npuconvert.zip -d npuconvert
          echo "NPUCONVERT_DIR=$GITHUB_WORKSPACE/tools/npuconvert/npuconvert" >> $GITHUB_ENV

      - name: Download model from Civitai
        env:
          CIVITAI_API_KEY: ${{ secrets.CIVITAI_API_KEY }}
        run: |
          set -euo pipefail
          VER_ID="${{ inputs.civitai_version_id }}"
          [ -n "$VER_ID" ] || { echo "You must provide civitai modelVersionId."; exit 1; }
          URL_INPUT="https://civitai.com/api/download/models/${VER_ID}"
          curl -L -H "Authorization: Bearer ${CIVITAI_API_KEY}" \
               -o "${{ inputs.filename }}" \
               --fail --retry 5 --retry-delay 5 \
               "$URL_INPUT"
          case "${{ inputs.filename }}" in
            *.safetensors) ;;
            *) echo "filename must end with .safetensors"; exit 1 ;;
          esac

      - name: Download QNN SDK v2.28.0.241029
        run: |
          set -euo pipefail
          mkdir -p "$GITHUB_WORKSPACE/qnn_sdk"
          cd "$GITHUB_WORKSPACE/qnn_sdk"
          curl -L -o qnn.zip "https://apigwx-aws.qualcomm.com/qsc/public/v1/api/download/software/qualcomm_neural_processing_sdk/v2.28.0.241029.zip"
          unzip -q qnn.zip
          
      - name: Fix npuconvert path and customize
        run: |
          set -euo pipefail
          BIN_FILE=$(find "$GITHUB_WORKSPACE/qnn_sdk" -type f -name "envsetup.sh" -print -quit || true)
          if [ -z "${BIN_FILE:-}" ]; then
            echo "### QNN envsetup.sh not found. Listing qnn_sdk structure (maxdepth 3) ###"
            find "$GITHUB_WORKSPACE/qnn_sdk" -maxdepth 3 -mindepth 1 -print
            exit 1
          fi
          echo "QNN_SDK_BIN=$(dirname "$BIN_FILE")" >> $GITHUB_ENV
          sed -i 's|cd /data/qairt/2.28.0.241029/bin|cd "$QNN_SDK_BIN"|' "$NPUCONVERT_DIR/scripts/convert_all.sh"
          if grep -q "^prompts\s*=" "$GITHUB_WORKSPACE/prompts.py"; then
            echo "### Replacing prompts block in prepare_data.py ###"
            PROMPTS_CONTENT=$(sed 's/[&/\]/\\&/g' "$GITHUB_WORKSPACE/prompts.py")
            sed -i '/^prompts\s*=\s*\[/,/^]/c\'"$PROMPTS_CONTENT" "$NPUCONVERT_DIR/prepare_data.py"
          else
            echo "### Skipping replacement ###"
          fi

      - name: Setup Python env with uv
        run: |
          cd "$NPUCONVERT_DIR"
          uv venv -p 3.10
          source .venv/bin/activate
          uv sync
          
      - name: Run (1) prepare_data.py
        run: |
          set -euo pipefail
          cd "$NPUCONVERT_DIR"
          source .venv/bin/activate
          python prepare_data.py --model_path "$GITHUB_WORKSPACE/${{ inputs.filename }}" --clip_skip "${{ inputs.clip_skip }}"
          echo "### Sample preview images ###" >> $GITHUB_STEP_SUMMARY
          count=0
          for img in "${{ env.NPUCONVERT_DIR }}"/images/*.png; do
            [ -e "$img" ] || continue
            b64=$(base64 -w0 "$img")
            echo "<img src=\"data:image/png;base64,$b64\" width=\"160\" style=\"margin:4px\" />" >> $GITHUB_STEP_SUMMARY
            count=$((count+1))
            [ $count -ge 6 ] && break
          done

      - name: Run (2) gen_quant_data.py
        run: |
          set -euo pipefail
          cd "$NPUCONVERT_DIR"
          source .venv/bin/activate
          python gen_quant_data.py

      - name: Run (3) export_onnx.py
        run: |
          set -euo pipefail
          cd "$NPUCONVERT_DIR"
          source .venv/bin/activate
          python export_onnx.py --model_path "$GITHUB_WORKSPACE/${{ inputs.filename }}" --clip_skip "${{ inputs.clip_skip }}"

      - name: Run (4) convert_all.sh
        run: |
          set -euo pipefail
          cd "$NPUCONVERT_DIR"
          source .venv/bin/activate
          bash scripts/convert_all.sh --min_soc "${{ inputs.min_soc }}"

      - name: Package outputs
        run: |
          cd "$NPUCONVERT_DIR"
          OUTDIR=$(ls -d output/qnn_models_* | tail -n 1)
          test -d "$OUTDIR"
          zip -r npu_models.zip "$OUTDIR"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: npu_models
          path: ${{ env.NPUCONVERT_DIR }}/npu_models.zip
          if-no-files-found: error
